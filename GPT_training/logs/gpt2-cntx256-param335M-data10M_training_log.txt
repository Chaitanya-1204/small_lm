============================================================
Model Summary Log
============================================================
Tokenizer Path: tokenizer/tokenizer_train10M.json
Model Name: gpt2-cntx256-param335M-data10M
Sequence Length: 256
Batch Size: 16
Num Epochs: 20
Warmup Steps: 2000
Total Training Steps: 76980
Total Model Parameters: 335.60M
Model Config:
  - Embedding Dim: 1024
  - Num Layers: 24
  - Num Heads: 16
  - Inner Dim: 4096
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 1
Seq Length: 256
Train Loss: 4.6635 | Perplexity: 106.0038
Eval  Loss: 4.2764 | Perplexity: 71.9822
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 2
Seq Length: 256
Train Loss: 3.7563 | Perplexity: 42.7879
Eval  Loss: 3.9496 | Perplexity: 51.9169
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 3
Seq Length: 256
Train Loss: 3.4704 | Perplexity: 32.1487
Eval  Loss: 3.7848 | Perplexity: 44.0288
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 4
Seq Length: 256
Train Loss: 3.2753 | Perplexity: 26.4517
Eval  Loss: 3.6731 | Perplexity: 39.3753
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 5
Seq Length: 256
Train Loss: 3.1188 | Perplexity: 22.6190
Eval  Loss: 3.6061 | Perplexity: 36.8222
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 6
Seq Length: 256
Train Loss: 2.9825 | Perplexity: 19.7373
Eval  Loss: 3.5602 | Perplexity: 35.1692
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 7
Seq Length: 256
Train Loss: 2.8666 | Perplexity: 17.5765
Eval  Loss: 3.5302 | Perplexity: 34.1313
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 8
Seq Length: 256
Train Loss: 2.7492 | Perplexity: 15.6299
Eval  Loss: 3.5182 | Perplexity: 33.7238
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 9
Seq Length: 256
Train Loss: 2.6341 | Perplexity: 13.9309
Eval  Loss: 3.5237 | Perplexity: 33.9087
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 10
Seq Length: 256
Train Loss: 2.5205 | Perplexity: 12.4350
Eval  Loss: 3.5305 | Perplexity: 34.1406
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 11
Seq Length: 256
Train Loss: 2.4253 | Perplexity: 11.3055
Eval  Loss: 3.5485 | Perplexity: 34.7614
============================================================

Early stopping triggered at epoch 11
============================================================
Final Test Results
Seq Length: 256
Test Loss: 3.3959 | Perplexity: 29.8414
============================================================
