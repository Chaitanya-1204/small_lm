============================================================
Model Summary Log
============================================================
Tokenizer Path: tokenizer/tokenizer_train10M.json
Model Name: gpt2-cntx256-param184M-data10M
Sequence Length: 256
Batch Size: 32
Num Epochs: 20
Warmup Steps: 2000
Total Training Steps: 38500
Total Model Parameters: 184.45M
Model Config:
  - Embedding Dim: 1024
  - Num Layers: 12
  - Num Heads: 16
  - Inner Dim: 4096
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 1
Seq Length: 256
Train Loss: 5.0852 | Perplexity: 161.6132
Eval  Loss: 4.4766 | Perplexity: 87.9308
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 2
Seq Length: 256
Train Loss: 3.9417 | Perplexity: 51.5083
Eval  Loss: 4.0675 | Perplexity: 58.4115
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 3
Seq Length: 256
Train Loss: 3.6123 | Perplexity: 37.0507
Eval  Loss: 3.8727 | Perplexity: 48.0740
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 4
Seq Length: 256
Train Loss: 3.4045 | Perplexity: 30.0988
Eval  Loss: 3.7474 | Perplexity: 42.4125
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 5
Seq Length: 256
Train Loss: 3.2414 | Perplexity: 25.5682
Eval  Loss: 3.6575 | Perplexity: 38.7659
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 6
Seq Length: 256
Train Loss: 3.1209 | Perplexity: 22.6660
Eval  Loss: 3.5878 | Perplexity: 36.1553
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 7
Seq Length: 256
Train Loss: 3.0088 | Perplexity: 20.2628
Eval  Loss: 3.5459 | Perplexity: 34.6724
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 8
Seq Length: 256
Train Loss: 2.9111 | Perplexity: 18.3764
Eval  Loss: 3.5135 | Perplexity: 33.5662
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 9
Seq Length: 256
Train Loss: 2.8294 | Perplexity: 16.9345
Eval  Loss: 3.4995 | Perplexity: 33.0982
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 10
Seq Length: 256
Train Loss: 2.7440 | Perplexity: 15.5497
Eval  Loss: 3.4885 | Perplexity: 32.7371
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 11
Seq Length: 256
Train Loss: 2.6790 | Perplexity: 14.5705
Eval  Loss: 3.4792 | Perplexity: 32.4333
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 12
Seq Length: 256
Train Loss: 2.6095 | Perplexity: 13.5917
Eval  Loss: 3.4776 | Perplexity: 32.3804
============================================q================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 13
Seq Length: 256
Train Loss: 2.5456 | Perplexity: 12.7507
Eval  Loss: 3.4802 | Perplexity: 32.4651
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 14
Seq Length: 256
Train Loss: 2.4962 | Perplexity: 12.1363
Eval  Loss: 3.4785 | Perplexity: 32.4123
============================================================

--------------------------------------------------------------------------------
============================================================
Training and Evaluation Results for Epoch 15
Seq Length: 256
Train Loss: 2.4496 | Perplexity: 11.5833
Eval  Loss: 3.4831 | Perplexity: 32.5607
============================================================

Early stopping triggered at epoch 15
============================================================
Final Test Results
Seq Length: 256
Test Loss: 3.3337 | Perplexity: 28.0406
============================================================
